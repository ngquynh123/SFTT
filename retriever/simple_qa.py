#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Simple QA without embeddings - Chá»‰ dÃ¹ng model LLM trá»±c tiáº¿p
"""

import sys, os
sys.path.append(os.path.dirname(__file__))

from model_llm import build_llm

def simple_qa(question: str):
    """QA Ä‘Æ¡n giáº£n khÃ´ng cáº§n embeddings"""
    
    print("ðŸš€ SIMPLE QA MODE (GPU Test)")
    print("=" * 50)
    
    # Kiá»ƒm tra GPU availability
    try:
        import torch
        if torch.cuda.is_available():
            print(f"ðŸ”¥ GPU Available: {torch.cuda.get_device_name(0)}")
            print(f"ðŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB")
            device = "cuda"
        else:
            print("ðŸ’» No GPU available, using CPU")
            device = "cpu"
    except:
        device = "cpu"
    
    # Load model trá»±c tiáº¿p vá»›i GPU
    try:
        llm = build_llm(
            model_path_or_id=r"D:\AI.LLM-khanh-no_rrf\models\phogpt4b-ft-merged-manual",
            device=device,
            temperature=0.0,
            max_new_tokens=24
        )
        print("âœ… Model loaded")
        
        # Táº¡o prompt Ä‘Æ¡n giáº£n hÆ¡n
        prompt = f"CÃ¢u há»i: {question}\nCÃ¢u tráº£ lá»i:"
        
        print(f"ðŸ¤” Question: {question}")
        print("â³ Generating...")
        
        # Generate answer
        answer = llm.generate(prompt, stop=["CÃ¢u há»i:", "Q:", "A:", "\n\n"])
        
        print(f"ðŸ’¡ Answer: {answer}")
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        
        # Fallback to original model
        try:
            print("ðŸ”„ Trying original model...")
            llm = build_llm(
                model_path_or_id=r"D:\AI.LLM-khanh-no_rrf\models\PhoGPT-4B",
                device=device, 
                temperature=0.0,
                max_new_tokens=24
            )
            
            prompt = f"CÃ¢u há»i: {question}\nCÃ¢u tráº£ lá»i:"
            answer = llm.generate(prompt, stop=["CÃ¢u há»i:", "\n\n"])
            print(f"ðŸ’¡ Answer: {answer}")
            
        except Exception as e2:
            print(f"âŒ Both models failed: {e2}")
            return "KhÃ´ng thá»ƒ tráº£ lá»i."

if __name__ == "__main__":
    if len(sys.argv) > 1:
        question = " ".join(sys.argv[1:])
    else:
        question = input("Q> ")
    
    simple_qa(question)