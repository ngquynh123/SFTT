#ch·∫°y code ki·ªÉu python test_em_lesson.py data/lesson/CTSC.json

import json
import sys
import numpy as np
from pathlib import Path
from sentence_transformers import SentenceTransformer

# ====== Load model Vi-bge ======
MODEL_ID = "AITeamVN/Vietnamese_Embedding"
model = SentenceTransformer(MODEL_ID)

def embed_texts(texts):
    """Sinh embedding t·ª´ danh s√°ch text"""
    return model.encode(
        texts,
        normalize_embeddings=True,  # cosine-friendly
        batch_size=32,
        show_progress_bar=False
    ).astype(np.float32)

def main():
    # ====== Nh·∫≠n ƒë∆∞·ªùng d·∫´n file qua terminal ======
    if len(sys.argv) < 2:
        print("‚ùå B·∫°n ch∆∞a nh·∫≠p ƒë∆∞·ªùng d·∫´n file JSON.")
        print("üëâ C√°ch d√πng: python test_em_lesson.py <path_toi_file_json>")
        sys.exit(1)

    input_path = Path(sys.argv[1])
    if not input_path.exists():
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {input_path}")
        sys.exit(1)

    # ====== Load d·ªØ li·ªáu ======
    try:
        with open(input_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        print(f"‚ùå L·ªói ƒë·ªçc JSON ·ªü {input_path}: {e}")
        sys.exit(1)

    # ====== Gom t·∫•t c·∫£ text c·ªßa chunks ƒë·ªÉ embed theo batch ======
    chunk_refs = []   # (doc_idx, chunk_idx)
    texts = []
    for di, doc in enumerate(data):
        chunks = doc.get("chunks", [])
        for ci, chunk in enumerate(chunks):
            text = (chunk.get("text") or "").strip()
            if text:
                chunk_refs.append((di, ci))
                texts.append(text)

    # Kh√¥ng c√≥ text h·ª£p l·ªá
    if not texts:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y 'text' h·ª£p l·ªá trong b·∫•t k·ª≥ chunk n√†o.")
    else:
        # ====== T·∫°o embeddings theo batch ======
        embs = embed_texts(texts)

        # ====== G√°n embed v·ªÅ l·∫°i t·ª´ng chunk ======
        for (di, ci), emb in zip(chunk_refs, embs):
            data[di]["chunks"][ci]["embed"] = emb.tolist()

        # V·ªõi chunk kh√¥ng c√≥ text ‚Üí set None
        for di, doc in enumerate(data):
            for ci, chunk in enumerate(doc.get("chunks", [])):
                if "embed" not in chunk:
                    chunk["embed"] = None

    # ====== Ghi ra JSON (gi·ªØ nguy√™n c·∫•u tr√∫c) ======
    out_dir = Path("embed_data/lesson/")
    out_dir.mkdir(parents=True, exist_ok=True)
    out_path = out_dir / f"{input_path.stem}_with_emb.json"

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"‚úÖ Done! ƒê√£ t·∫°o file {out_path}")

if __name__ == "__main__":
    main()
